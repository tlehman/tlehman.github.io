<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics on tlehman@home</title>
    <link>/categories/statistics/index.xml</link>
    <description>Recent content in Statistics on tlehman@home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="/categories/statistics/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Gun control and safety</title>
      <link>/blog/2015/10/01/gun-control-and-safety/</link>
      <pubDate>Thu, 01 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>/blog/2015/10/01/gun-control-and-safety/</guid>
      <description>&lt;p&gt;Another mass shooting happened today. I don&amp;rsquo;t usually write about this, but it happened in Roseberg, Oregon, close to where I live. Too close. I do understand that it is morally equivalent to a mass shooting in Ethiopia, Indonesia, the Netherlands or Australia, but something about events being close by have a bigger emotional impact.&lt;/p&gt;

&lt;p&gt;The question I want to address in this article is whether legislation can help solve this problem. I&amp;rsquo;ll focus on whether it is effective to implement barriers to gun ownership.&lt;/p&gt;

&lt;p&gt;The inspiration for this article is this graphic by Libby Isenstein:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://pbs.twimg.com/media/COF4FxPUkAEmOkI.jpg&#34; alt=&#34;Libby Isenstein&#39;s infographic on guns&#34; /&gt;&lt;/p&gt;

&lt;p&gt;My methodology is to see if there is a correlation between the number of gun-control-related laws in a state and the number of gun-related deaths. The columns in the above table will each count for up to one point. For example, if a state doesn&amp;rsquo;t require a permit for a gun, it gets 0, and if it does require a permit, it gets 1. For columns related to the difficulty of getting a gun, easy gets 0 points, moderate gets 0.5 points, and difficult gets 1 point.&lt;/p&gt;

&lt;p&gt;These points are then added up, and we look at all the states (plus DC), as pairs &lt;code&gt;(sum of points, gun deaths per 100,000 people)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/images/blogimg/guns_output_6_1.png&#34; alt=&#34;scatterplot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This has a correlation coefficient of 0.52 (1.0 being a perfect fit), what that means is that there is a moderate trend between the degree of gun control and the number of gun-related deaths. It doesn&amp;rsquo;t prove that gun control laws cause fewer gun deaths, but it is at least consistent with that claim. And more importantly, it is evidence against the argument that more widespead access to guns make us all safer.&lt;/p&gt;

&lt;p&gt;No person should die for no reason. If legislation can help solve this problem (there&amp;rsquo;s reason to think it can), then it&amp;rsquo;s our duty to make that come to pass. Unfortunately, certain interpretations of the Second Amendment currently in force have prevented many sane limits on access to guns, this article by &lt;a href=&#34;https://www.washingtonpost.com/opinions/the-five-extra-words-that-can-fix-the-second-amendment/2014/04/11/f8a19578-b8fa-11e3-96ae-f2c36d2b1245_story.html?postshare=2541443818572894&#34;&gt;John Paul Stevens in the Washington Post explain a little history behind that&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For more detail on how to perform the analysis above, see below (requires familiarity with python, or a similar language).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import pandas as pd
import numpy as np
df = pd.read_csv(&amp;quot;guns.csv&amp;quot;)
df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;deaths&lt;/th&gt;
      &lt;th&gt;state&lt;/th&gt;
      &lt;th&gt;laws&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;2.6&lt;/td&gt;
      &lt;td&gt;HI&lt;/td&gt;
      &lt;td&gt;7.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;3.1&lt;/td&gt;
      &lt;td&gt;MA&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;4.2&lt;/td&gt;
      &lt;td&gt;NY&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;4.4&lt;/td&gt;
      &lt;td&gt;CT&lt;/td&gt;
      &lt;td&gt;4.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;5.3&lt;/td&gt;
      &lt;td&gt;RI&lt;/td&gt;
      &lt;td&gt;4.5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import matplotlib.pyplot as plt
%matplotlib inline
plt.ylabel(&amp;quot;gun deaths per 100k&amp;quot;)
plt.xlabel(&amp;quot;number of gun laws&amp;quot;)
plt.scatter(df[&amp;quot;laws&amp;quot;], df[&amp;quot;deaths&amp;quot;])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.collections.PathCollection at 0x10d678850&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/images/blogimg/guns_output_3_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Since it looks like a downward trend, let&amp;rsquo;s see how well a linear model fits this data.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
from sklearn import linear_model
reg = linear_model.LinearRegression() 
X = df[&#34;laws&#34;].values.reshape((len(df),1))
y_true = df[&#34;deaths&#34;].values.reshape((len(df),1))

reg.fit(X,y_true)
y_pred = reg.predict(X)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.ylabel(&amp;quot;gun deaths per 100k&amp;quot;)
plt.xlabel(&amp;quot;number of gun laws&amp;quot;)
plt.plot(X,y_pred)
plt.scatter(X,y_true)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.collections.PathCollection at 0x10e980fd0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/images/blogimg/guns_output_6_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;It looks like a really good, fit, but to make it precist, we should find the $R^2$ score.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.metrics import r2_score
r2_score(y_true, y_pred)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.52124939556633598
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian Drunk Driving</title>
      <link>/blog/2015/04/23/bayesian-drunk-driving/</link>
      <pubDate>Thu, 23 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>/blog/2015/04/23/bayesian-drunk-driving/</guid>
      <description>

&lt;p&gt;Driving drunk is illegal for a good reason, it&amp;rsquo;s way riskier than driving sober. This article isn&amp;rsquo;t about driving drunk
though, it&amp;rsquo;s more about the sloppy thought processes that can too easily confuse something as obvious as that first
sentence. Here&amp;rsquo;s an example of a bogus argument that appears to support the idea that drunk driving is actually safer:&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;en&#34;&gt;
&lt;p&gt;From a recent talk: &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; of accidents involve drunk drivers, so &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; don’t =&amp;gt; sober drivers 2× as bad.&lt;/p&gt;
&amp;mdash; Colin Beveridge (@icecolbeveridge)
&lt;a href=&#34;https://twitter.com/icecolbeveridge/status/587317304335147008&#34;&gt;April 12, 2015&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;So the argument is as follows: In 2012, 10,322 people were killed in alcohol-impaired driving crashes,
accounting for nearly one-third (31%) of all traffic-related deaths in the United States [1].
That means that approximately one third of traffic-related deaths involve drunk driving, meaning that
two thirds of traffic-related deaths don&amp;rsquo;t involve drunk driving. Therefore, sober drivers are twice as
likely to die in a traffic accident.&lt;/p&gt;

&lt;p&gt;If you think something is wrong with that argument, you are right, but it&amp;rsquo;s not just because the conclusion
intuitively seems wrong, it&amp;rsquo;s because it involves a mistake in conditional probability. To see the mistake,
it helps to introduce a litle notation, we will define:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;P(D) to be the probability that a person is drunk&lt;/li&gt;
&lt;li&gt;P(A) to be the probability that a person will die in a traffic-related accident&lt;/li&gt;
&lt;li&gt;P(D | A) &lt;em&gt;(pronounced probability of D given A)&lt;/em&gt; is the probability that a person is drunk, given that
there was a death in a traffic-related accident they were in&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So using the 2012 CDC data, we can assign 31%, P(D | A) = 0.31. This is that the probability of a drunk
driver being involved &lt;strong&gt;given that there was a deadly driving accident&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The first thing to point out is that the statement that &amp;lsquo;sober drivers are twice as likely as drunk drivers
to die in an accident&amp;rsquo; is really a statement about P(A | D), that is, the probability of a deadly driving
accident &lt;strong&gt;given that that person is drunk&lt;/strong&gt;. We don&amp;rsquo;t know this yet, however, we can figure it out using
Bayes&amp;rsquo; theorem.&lt;/p&gt;

&lt;h2 id=&#34;bayes-theorem&#34;&gt;Bayes&amp;rsquo; Theorem&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Bayes%27_theorem&#34;&gt;Bayes&amp;rsquo; Theorem&lt;/a&gt; is unusual in that it is extremely useful
and easy to prove, but hard to really understand.
This is something I learned several times in college, but never really understood it&amp;rsquo;s importance until much
later. To see how easy to prove it is, we go back to the definition of conditional probability:&lt;/p&gt;

&lt;p&gt;{% latex %}
$P(X|Y) = P(X \cap Y)/P(Y)$
{% endlatex %}&lt;/p&gt;

&lt;p&gt;Where P(X &amp;cap; Y) is the probability of X and Y occurring. Since this is true for any pair of events X and Y,
we can reverse them and get&lt;/p&gt;

&lt;p&gt;{% latex %}
$P(Y|X) = P(Y \cap X)/P(X)$
{% endlatex %}&lt;/p&gt;

&lt;p&gt;Also, remember that AND is commutative, so that P(X &amp;cap; Y) = P(Y &amp;cap; X), so we can multiply the above two
equations by P(Y) and P(X), respectively, to get:&lt;/p&gt;

&lt;p&gt;{% latex %}
$P(X|Y)P(Y) = P(X \cap Y) = P(Y \cap X) = P(Y|X)P(X)$
{% endlatex %}&lt;/p&gt;

&lt;p&gt;This relates P(X|Y) to P(Y|X), P(X) and P(Y), we can solve the above equation to get:&lt;/p&gt;

&lt;p&gt;{% latex %}
$P(X|Y) = {P(Y|X)P(X)\over P(Y)}$
{% endlatex %}&lt;/p&gt;

&lt;p&gt;And that&amp;rsquo;s it, we took the definition of conditional probability, did a little algebra, and out popped Bayes&amp;rsquo;
theorem, we can now apply this to the above drunk driving fallacy, and calculate the probability that we are
interested in, that is, P(A | D).&lt;/p&gt;

&lt;p&gt;{% latex %}
$P(A|D) = {P(D|A)P(A)\over P(D)}$
{% endlatex %}&lt;/p&gt;

&lt;p&gt;Since we know P(D|A), we just need to find P(A) and P(D). Since the CDC data we are using is annual data,
we need to take the number of casualties from deadly accidents in the United States for the year of 2012 (33,561)
and divide by the number of drivers (211,814,830), that gives an estimate of P(A) = 33,&lt;sup&gt;561&lt;/sup&gt;&amp;frasl;&lt;sub&gt;211&lt;/sub&gt;,814,830 =
0.0001584, which is about 1 in 6,313.&lt;/p&gt;

&lt;p&gt;Next, we need to find the probability that a driver is drunk P(D), we will use the data from the study
referenced in [3], and define &amp;lsquo;drunk&amp;rsquo; to be a BAC of &amp;geq; 0.1%. Then P(D) = 0.00387 or about 1 in 258 (more
on this calculation in the notes below).&lt;/p&gt;

&lt;p&gt;Now that we have:&lt;/p&gt;

&lt;p&gt;P(D|A) = 0.31 (* probability of a driver being drunk, given they were involved in an accident where someone died *),&lt;/p&gt;

&lt;p&gt;P(A) = 0.0001584 (* probability of a driver being involved in an accident where someone died *), and&lt;/p&gt;

&lt;p&gt;P(D) = 0.00387 (* probability of a driver being drunk *)&lt;/p&gt;

&lt;p&gt;We can figure out P(A|D) (* probability of a drunk driver getting into a deadly accident *)&lt;/p&gt;

&lt;p&gt;P(A|D) = P(D|A)P(A)/P(D) = (0.31*0.0001584)/0.00387 = 0.0127 (1.27 %)&lt;/p&gt;

&lt;p&gt;1.27% is not insignificant, it&amp;rsquo;s about half the probability of rolling snake eyes in craps.
Now, let&amp;rsquo;s compare that to sober driving, we just need to calculate P(A|D&lt;sup&gt;c&lt;/sup&gt;). We can use &lt;a href=&#34;https://en.wikipedia.org/wiki/Law_of_total_probability&#34;&gt;Kolmogorov&amp;rsquo;s
Theorem of total probability&lt;/a&gt;, shuffle a few terms to
get:&lt;/p&gt;

&lt;p&gt;P(A|D&lt;sup&gt;c&lt;/sup&gt;) = (P(A) - P(A|D)P(D))/P(D&lt;sup&gt;c&lt;/sup&gt;) = (0.0001584 - 0.0127*0.00387)/(1-0.00387) = .000109,
which is about 1 in 9118.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;So the probability of getting in a deadly accident, given that you are drunk is 1.27%, and the probability of getting into
a deadly accident, given that you are not drunk is .01%, that means that it is 127 times more likely that you will get into
a deadly accident while drunk.&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;[1] Impaired Driving: Get the Facts &lt;em&gt;Centers for Disease Control&lt;/em&gt;
&lt;a href=&#34;http://www.cdc.gov/Motorvehiclesafety/impaired_driving/impaired-drv_factsheet.html&#34;&gt;
[link]
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] Total licensed drivers &lt;em&gt;U.S. Department of Transportation Federal Highway Administration&lt;/em&gt;
&lt;a href=&#34;http://www.fhwa.dot.gov/policyinformation/statistics/2012/dl22.cfma&#34;&gt;
[link]
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] Probability of arrest while driving under the influence (George A Beitel, Michael C Sharp, William D Glauz)
&lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1730617/pdf/v006p00158.pdf&#34;&gt;
[link]
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes on [3], we don&amp;rsquo;t technically have P(D), but we do have P(D|A&lt;sub&gt;1&lt;/sub&gt;), P(A&lt;sub&gt;1&lt;/sub&gt;),
and P(A&lt;sub&gt;1&lt;/sub&gt;|D), where A&lt;sub&gt;1&lt;/sub&gt; is the event that a person is arrested. We can then find
P(D) = (P(D|A&lt;sub&gt;1&lt;/sub&gt;)P(A&lt;sub&gt;1&lt;/sub&gt;))/P(A&lt;sub&gt;1&lt;/sub&gt;|D) = (0.06&amp;times;0.000374)/0.0058 =
.00387&lt;/em&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Standing desk histogram</title>
      <link>/blog/2014/12/31/standing-desk-histogram/</link>
      <pubDate>Wed, 31 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/blog/2014/12/31/standing-desk-histogram/</guid>
      <description>&lt;p&gt;A while back I wrote about a program to &lt;a href=&#34;/blog/2014/08/18/script-for-logging-standing-desk-state-transitions/&#34;&gt;record changing the state of an adjustible height standing desk&lt;/a&gt;
after about 3 months of gathering data on how long my desk is in the &lt;code&gt;up&lt;/code&gt; state, I found this:&lt;/p&gt;

&lt;p&gt;{% img /images/blogimg/standing_histogram.png %}&lt;/p&gt;

&lt;p&gt;With a mean of 54 minutes, 6 seconds, I usually stand for under an hour at a time.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m not sure if this is too much or too little. More research needed.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Analyzing Bash History and Fixing Typos</title>
      <link>/blog/2013/06/18/analyzing-bash-history-and-fixing-typos/</link>
      <pubDate>Tue, 18 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/blog/2013/06/18/analyzing-bash-history-and-fixing-typos/</guid>
      <description>&lt;p&gt;At the command line, I frequently type things too fast, and typos abound. A single character can mean the difference between showing documentation and deleting files (&lt;code&gt;rm&lt;/code&gt; vs &lt;code&gt;ri&lt;/code&gt;), so autocorrect is definitely a bad idea in this context.&lt;/p&gt;

&lt;p&gt;Instead of a generic autocorrect, a better idea is to find the most common mistakes. To do so, I used frequency analysis like in &lt;a href=&#34;/blog/2013/01/28/reinventing-the-wheel-or-how-i-learned-to-stop-coding-and-read-the-manpages/&#34;&gt;this post&lt;/a&gt; to narrow down what I use most at the shell:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cat ~/.bash_history | 
     awk -F\| &#39;{print $1}&#39; | 
     sort | 
     uniq -c | 
     sort -n | 
     tail -15

 157 rake routes
 221 dbtt
 232 git fetch -p
 300 rails c
 370 gi ts
 376 g gs
 403 git add .
 405 rails s
 406 git b
 433 exit
 435 git lg
 663 git diff
1112 ls
1898 clear
4486 git s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice that &lt;code&gt;gi ts&lt;/code&gt; is extremely common, I meant to type &lt;code&gt;git s&lt;/code&gt; all those 376 times. As a solution, I could just alias it, but I would prefer a more general solution that would handle &lt;code&gt;gi tdiff&lt;/code&gt; and &lt;code&gt;gi tb&lt;/code&gt; as &lt;code&gt;git diff&lt;/code&gt; and &lt;code&gt;git b&lt;/code&gt; respectively.&lt;/p&gt;

&lt;p&gt;I made the following script called &lt;code&gt;~/bin/gi&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/sh

if   [[ $1 =~ &#39;ts&#39; ]]; then
  git s
elif [[ $1 =~ &#39;tb&#39; ]]; then
  git b 
elif [[ $1 =~ &#39;tdiff&#39; ]]; then
  git diff
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So that &lt;code&gt;gi ts&lt;/code&gt; is no longer a mistake, it means what I meant it to mean. This saves me a few keystrokes, and it is a good example of why scripts in your path are generally better than aliases, since you can have logic in them.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lies Damned Lies and Statistics</title>
      <link>/blog/2013/04/03/lies-damned-lies-and-statistics/</link>
      <pubDate>Wed, 03 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/blog/2013/04/03/lies-damned-lies-and-statistics/</guid>
      <description>&lt;p&gt;There is a quote, usually attributed to Mark Twain that goes something
like:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;There are three kinds lies.
Lies, Damned Lies, and Statistics.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;My interpretation of this is that statistics are supposed to be the
worst kind of lie, or that the worst kinds of lies use
statistics.&lt;/p&gt;

&lt;p&gt;The thing that bothers me most about this quote (and the innumerable
minor variations of it that get repeated) is that the word
&amp;lsquo;statistics&amp;rsquo; comes at the end.&lt;/p&gt;

&lt;p&gt;Why does that matter? Notice that the list is presented as a sequence,
an increasing sequence of damned-ness, and the presence of the word
&amp;lsquo;statistics&amp;rsquo; at the end is supposed to imply that it is &amp;lsquo;more damned&amp;rsquo;
than damned lies.&lt;/p&gt;

&lt;p&gt;This interpretation bothers me because the implied damned-ness is
based on the initial correlation, and that correlation is only based
on two data points. The quote depends on a misunderstanding of
statistics. Anyone who has studied a little bit of statistics will
know not to trust an inference based on a correlation in a data set
of only two points!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Optimize your vote using statistics</title>
      <link>/blog/2012/09/04/optimize-your-vote-using-statistics/</link>
      <pubDate>Tue, 04 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>/blog/2012/09/04/optimize-your-vote-using-statistics/</guid>
      <description>&lt;p&gt;I used to hate the phrase &amp;ldquo;throwing your vote away.&amp;rdquo;. This is usually
used in response to people voting for someone who is probably not going
to win. Even though we have &lt;a href=&#34;http://en.wikipedia.org/wiki/List_of_political_parties_in_the_United_States#Major_political_parties&#34;&gt;five major parties&lt;/a&gt; in the United States, chances are, the winner is going to either a Republican or a Democrat.&lt;/p&gt;

&lt;p&gt;The reason I hated that phrase so much is that it discourages people
from voting for their ideal candidate for pragmatic reasons. Chances
are, a non-Democrat, non-Republican is not going to win, so cut your
losses and pick a candidate that you &lt;em&gt;dislike least&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;However, as I&amp;rsquo;ve gotten slightly older, I have come to appreciate how
necessary compromise is. What has me more hopeful is that you can
compromise with precision. I&amp;rsquo;ll explain what I mean by first giving some
context.&lt;/p&gt;

&lt;p&gt;Scott Hanselman &lt;a href=&#34;https://twitter.com/shanselman/status/243032228655951872&#34;&gt;mentioned this site on twitter today&lt;/a&gt; called &lt;a href=&#34;http://isidewith.com&#34;&gt;isidewith.com&lt;/a&gt;. It asks you a series of questions about issues that frequently arise in political debates. It then asks you to rate the importance of the issues, and then gives you a list of the percent with which you agree with all the candidates running for Present in 2012.&lt;/p&gt;

&lt;p&gt;So, you can choose your ideal candidate based on how many issues you agree on. For example, I answered the questions and got this as a match:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Gary Johnson 83%&lt;/li&gt;
&lt;li&gt;Jill Stein 82%&lt;/li&gt;
&lt;li&gt;Barack Obama 81%&lt;/li&gt;
&lt;li&gt;Mitt Romney 31%&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From these results, it looks like a very close call between Johnson,
Stein and Obama. Based on these results, my ideal candidate is probably
one of these three.&lt;/p&gt;

&lt;p&gt;So here is where we can compromise with precision, since I have three
almost identical matches (with respect to the battery of questions I
answered about various political issues). I can now decide which of
these three to vote on based on the likelihood they will win.&lt;/p&gt;

&lt;p&gt;The original reason I was so bothered by this is was that I thought that
ideals determined &lt;em&gt;one and only one&lt;/em&gt; ideal candidate. But by letting
data about the issues determine which candidates were ideal, I
allow for the possibility of multiple near-ideal matches.&lt;/p&gt;

&lt;p&gt;Then, given the set of near ideal matches, I can take into account which
is most likely to win, and cast my vote accordingly.&lt;/p&gt;

&lt;p&gt;So, let&amp;rsquo;s get to some statistics, since my title promised it, and
because we can use this to actually calculate who you should vote for.
In fact, if a good enough model can be generated to this effect, perhaps
we could replace voting for a single individual with taking a test, and
having a computer calculate your vote for you. That would be a much
better way to have the candidate reflect the majority views in the
United States.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start with some definitions, the &lt;strong&gt;expected value&lt;/strong&gt; of a random
variable X, where X can take on any of the n values {x&lt;sub&gt;1&lt;/sub&gt;, &amp;hellip; x&lt;sub&gt;n&lt;/sub&gt;}
with corresponding probabilities {p&lt;sub&gt;1&lt;/sub&gt;, &amp;hellip; p&lt;sub&gt;n&lt;/sub&gt;}, is
just the sum of those probabilities, times the corresponding value:&lt;/p&gt;

&lt;p&gt;{% latex %}
  $ E(X) = \sum_{i=1}^n p_ix_i $
{% endlatex %}&lt;/p&gt;

&lt;p&gt;So the expected value is a sort of weighted average over all of the
values the random variable could take on. The part of this I will be
using is the p&lt;sub&gt;i&lt;/sub&gt; factor. Given this definition, there
naturally follows an &amp;ldquo;expected maximum&amp;rdquo;, denoted Emax(X).&lt;/p&gt;

&lt;p&gt;{% latex %}
  $ Emax(X) = \max{ p_ix&lt;em&gt;i }&lt;/em&gt;{i=1}^n $
{% endlatex %}&lt;/p&gt;

&lt;p&gt;I make a further modification to
this model and use the &lt;strong&gt;issues coefficient&lt;/strong&gt; c&lt;sub&gt;i&lt;/sub&gt;. For example, I was an 83% match with Gary Johnson, so if Johnson is represented by the value x&lt;sub&gt;i&lt;/sub&gt;, then c&lt;sub&gt;i&lt;/sub&gt; = 0.83.&lt;/p&gt;

&lt;p&gt;So, using this model we have two values that need to be accounted
for before we can decide who to vote for, there is p&lt;sub&gt;i&lt;/sub&gt;, which is the probability that the i-th candidate will win, and then there is c&lt;sub&gt;i&lt;/sub&gt;, the degree to which the voter agrees with the candidate on the relevant issues. Since we don&amp;rsquo;t know who is going to win, we set all x&lt;sub&gt;i&lt;/sub&gt; = 1, and we can ignore that altogether, so the expected maximum becomes:&lt;/p&gt;

&lt;p&gt;{% latex %}
  $ Emax(X) = \max{ c_ip&lt;em&gt;i }&lt;/em&gt;{i=1}^n $
{% endlatex %}&lt;/p&gt;

&lt;p&gt;Now, in my case, I have all of the four c&lt;sub&gt;i&lt;/sub&gt; values, but I don&amp;rsquo;t
have the p&lt;sub&gt;i&lt;/sub&gt; values. To find these values, we could start with
the number of electoral representatives per party. I have not been able to find
this data, but If I did, I could calculate the perfect choice of a vote,
one that would be balanced between idealism and pragmatism.&lt;/p&gt;

&lt;p&gt;Note: If any of you can find data on the number of electoral
representatives per political party, I will happily make this into an
app that will calculate a suggestion based on this model. It will take
your &lt;a href=&#34;http://isidewith.com&#34;&gt;isidewith.com&lt;/a&gt; data and then weigh that with
the proportion of electoral votes for the corresponding party.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>